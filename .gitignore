out
llama2.c-stories15M
run
stories*
__pycache__